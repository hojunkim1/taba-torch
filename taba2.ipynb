{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYStMNa77N8n"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# gpu가 되는지 확인\n",
    "torch.backends.mps.is_available()"
   ],
   "metadata": {
    "id": "gbuo4FHL71GI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 디바이스를 cuda로 설정\n",
    "device = torch.device(\"mps\", 0)"
   ],
   "metadata": {
    "id": "8YptvCfV8HKJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# MNIST 데이터셋 다운로드\n",
    "train_dataset = MNIST(root=\"MNIST_data/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = MNIST(root=\"MNIST_data/\", train=False, transform=transforms.ToTensor(), download=True)"
   ],
   "metadata": {
    "id": "ZBiea4D08SAz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=128,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=128,\n",
    "                         shuffle=True)"
   ],
   "metadata": {
    "id": "nX60FBvG9R95"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tensor"
   ],
   "metadata": {
    "id": "0by7pYOl9tfm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "numpy"
   ],
   "metadata": {
    "id": "tWo4-EpO97hZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "a = np.ones((5, 2))\n",
    "print(a)"
   ],
   "metadata": {
    "id": "CKMSHxyD9uu7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "numpy -> tensor"
   ],
   "metadata": {
    "id": "ZSI1Onka-EoZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "b = torch.from_numpy(a)\n",
    "print(b)"
   ],
   "metadata": {
    "id": "Cqlwg69o-APW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "tensor -> numpy"
   ],
   "metadata": {
    "id": "TltMkdO3-ap2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "aa = b.numpy()\n",
    "print(aa)"
   ],
   "metadata": {
    "id": "yvr92WEW-LWK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "img = train_dataset[13335][0].numpy()\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "7cIXVWNC-hzf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multi Layer Perceptron"
   ],
   "metadata": {
    "id": "sd99c6sk_bzW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 28x28x1 => 10\n",
    "mnist_fc_model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=28 * 28 * 1, out_features=256),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(in_features=256, out_features=10),\n",
    "    nn.Softmax()\n",
    ")"
   ],
   "metadata": {
    "id": "Gz9HHVUz-7xW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "mnist_fc_model.to(device)"
   ],
   "metadata": {
    "id": "7fEmyQ0EAJek"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train 함수"
   ],
   "metadata": {
    "id": "Uz69bkj7Aj7P"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch import optim\n",
    "import time\n",
    "\n",
    "\n",
    "def train(model, train_loader):\n",
    "    # 학습할 epochs수를 정하기\n",
    "    epochs = 10\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # model을 train모드로 변경\n",
    "        model.train()\n",
    "        print(f'epochs:{str(epoch + 1)} / {str(epochs)}')\n",
    "\n",
    "        for samples in train_loader:\n",
    "            x_t, y_t = samples\n",
    "            # 이 데이터들도 device(cuda)로 보내자\n",
    "            x_t = x_t.to(device)\n",
    "            y_t = y_t.to(device)\n",
    "\n",
    "            pred = model(x_t)\n",
    "            # pred랑 실제 값이랑 얼마나 차이나는지 = loss\n",
    "            loss = criterion(pred, y_t)\n",
    "\n",
    "            # optimizer를 이용해서 학습(역전파)을 진행\n",
    "            optimizer.zero_grad()  # optimizer를 초기화\n",
    "            loss.backward()  # 역전파 진행\n",
    "            optimizer.step()  # 역전파된 것을 기반으로 가중치 업데이트\n",
    "\n",
    "        # 하나의 epoch에 대해서 학습이 완료\n",
    "        # 현재 성능이 어느정도인지 확인하는 코드\n",
    "        model.eval()  # model을 이제 평가하는 모드로 변경\n",
    "        correct = 0\n",
    "        for samples in train_loader:\n",
    "            xx, yy = samples\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)  # 5\n",
    "            pred = model(xx)  # [0, 0, 0, 0.1, 0.1, 0, 0, 0.8, 0, 0]\n",
    "            _, predicted = torch.max(pred, 1)  # 7\n",
    "            correct += predicted.eq(yy.data).sum()\n",
    "\n",
    "        print(f'train_accuracy: {(100. * correct / len(train_loader.dataset)).item()}')\n",
    "\n",
    "        end_time = time.time()\n",
    "        지난시간 = end_time - start_time\n",
    "        분 = int(지난시간 // 60)  # // 몫\n",
    "        초 = int(지난시간 % 60)  # % 나머지\n",
    "        print(f'현재까지 학습하는데 걸린 시간: {분}분 {초}초')"
   ],
   "metadata": {
    "id": "fbCmp7rpAeek"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train(mnist_fc_model, train_loader)"
   ],
   "metadata": {
    "id": "hkVihKQrA5p2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 우리가 만든 모델의 복잡도를 계산하기"
   ],
   "metadata": {
    "id": "uHIUEyLXFyjT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def 복잡도계산(model):\n",
    "    pp = 0\n",
    "    # 모델에서 parameter를 하나하나 불러옵니다\n",
    "    for p in list(model.parameters()):\n",
    "        nn = 1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn * s\n",
    "        pp += nn\n",
    "\n",
    "    # parameter 수를 출력해줄 것\n",
    "    return pp"
   ],
   "metadata": {
    "id": "Pu1DXaAdFSpd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "복잡도계산(mnist_fc_model)"
   ],
   "metadata": {
    "id": "Bbd2SueCGP7s"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN을 만들어봅시다"
   ],
   "metadata": {
    "id": "rIiBf1prG4o7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "mnist_cnn_model = nn.Sequential(\n",
    "    # input 1x28x28\n",
    "    # CNN 모델에서 CNN부분\n",
    "    nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, padding=0),\n",
    "    nn.ReLU(),  # 활성화함수는 Sigmoid대신 ReLU를 사용해보자\n",
    "    nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, padding=0),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    # CNN 모델에서 MLP부분\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=24 * 24 * 8, out_features=48),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=48, out_features=10),\n",
    "    nn.Softmax()  # 마지막은 무조건 softmax\n",
    ")"
   ],
   "metadata": {
    "id": "cB1eyxUwGUzv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "복잡도계산(mnist_cnn_model)"
   ],
   "metadata": {
    "id": "TxzC5gAzH_Kx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "mnist_cnn_model.to(device)\n",
    "train(mnist_cnn_model, train_loader)"
   ],
   "metadata": {
    "id": "7xdHzVQrIBm3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Le-Net5 모델 만들기"
   ],
   "metadata": {
    "id": "YwOr4SGugKIi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "lenet = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "    nn.Tanh(),  # 하이퍼볼릭 탄젠트를 활성화함수(activation funciton)로 사용\n",
    "    nn.AvgPool2d(kernel_size=2),\n",
    "\n",
    "    nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "    nn.Tanh(),\n",
    "    nn.AvgPool2d(kernel_size=2),\n",
    "\n",
    "    nn.Conv2d(in_channels=16, out_channels=120, kernel_size=4, stride=1),\n",
    "    nn.Tanh(),\n",
    "\n",
    "    # 1x1짜리 feature로 나오게 된다\n",
    "    # flatten 후 MLP를 설정\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=120, out_features=84),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(in_features=84, out_features=10),\n",
    "    nn.Softmax()\n",
    ")"
   ],
   "metadata": {
    "id": "45x2IfI8Ihue"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "복잡도계산(lenet)"
   ],
   "metadata": {
    "id": "YWhiGATHmmHz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "lenet.to(device)\n",
    "train(lenet, train_loader)"
   ],
   "metadata": {
    "id": "gV_77TtImr6I"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "lenet - 4만개 가량 - 95%   \n",
    "mlp - 20만개 가량 - 93%.  \n",
    "cnn - 22만개 가량 - 84%.  "
   ],
   "metadata": {
    "id": "wom69Rh3n7hm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "# summary(lenet, input_size=(1, 28, 28))"
   ],
   "metadata": {
    "id": "t5zwfOhFoW6a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN을 많이 쌓아서 성능을 올릴수 있다"
   ],
   "metadata": {
    "id": "IOX41IB6oSKx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class SimpleConvNet1(nn.Module):\n",
    "    def __init__(self):\n",
    "        # 초기화 함수\n",
    "        super().__init__()\n",
    "        self.CNN = nn.Sequential(\n",
    "            # stage1\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # stage2\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # stage3\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=4, stride=4),\n",
    "        )\n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=64, out_features=256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=256, out_features=10),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    # forward\n",
    "    def forward(self, inp):\n",
    "        cnn_res = self.CNN(inp)\n",
    "        fc_res = self.FC(cnn_res)\n",
    "        return fc_res"
   ],
   "metadata": {
    "id": "rnH00K3BnTa3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "convnet1 = SimpleConvNet1()"
   ],
   "metadata": {
    "id": "H0VdyyX-q9JM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# summary(convnet1, (1, 28, 28))"
   ],
   "metadata": {
    "id": "a2cFb1atrKxK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "convnet1.to(device)\n",
    "train(convnet1, train_loader)"
   ],
   "metadata": {
    "id": "2lcJzS-ZrNZt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test하는 함수를 만들어보자\n",
    "train dataset으로 지금까지 정확도가 얼마인지 알아봤었다.  \n",
    "test dataset으로 한번 정확도를 확인해보자"
   ],
   "metadata": {
    "id": "ph_zUNgivuCC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def test(model, loader):\n",
    "    # with 안에있는 모든 코드는 가중치 업데이트를 하지 않는다\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # 평가모드로 model 변경\n",
    "        correct = 0\n",
    "        for samples in loader:\n",
    "            xx, yy = samples\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "\n",
    "            pred = model(xx)  # [0,0,0,0,0,0,0,0.8,0.1,0.1]\n",
    "            _, predicted = torch.max(pred, 1)  # 7\n",
    "            correct += predicted.eq(yy.data).sum()\n",
    "        print(f'test accuracy: {(100. * correct / len(loader.dataset)).item()}')"
   ],
   "metadata": {
    "id": "A4oLtgY2rYWf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test(convnet1, test_loader)"
   ],
   "metadata": {
    "id": "9NnrRkppwyNs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 학습된 ResNet18을 가져와서 매우 적은 숫자의 FashionMNIST를 학습시키자"
   ],
   "metadata": {
    "id": "nBS8zoYg1QM1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "fashion_mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 이미지를 가져와서 tensor로 변환\n",
    "    transforms.Resize(224)  # 이미지를 224x224로 리사이즈\n",
    "])"
   ],
   "metadata": {
    "id": "i7ujz7s6w3dq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset2 = FashionMNIST('./', transform=fashion_mnist_transform,\n",
    "                              train=True, download=True)\n",
    "\n",
    "test_dataset2 = FashionMNIST('./', transform=fashion_mnist_transform,\n",
    "                             train=False, download=True)"
   ],
   "metadata": {
    "id": "MzFgfbO41t9F"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "60000개의 데이터중에서 5000개만 사용하도록 train dataset을 분리.  \n",
    "이후 5000개로 분리된 데이터셋만 사용해서 finetuning, transfer learning을 하자"
   ],
   "metadata": {
    "id": "YYvFmF6g2Wrm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_dataset1, train_dataset2 = random_split(train_dataset2, [5000, 55000])"
   ],
   "metadata": {
    "id": "R1JLobx92GU7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader2 = DataLoader(dataset=train_dataset1,\n",
    "                           batch_size=128,\n",
    "                           shuffle=True)\n",
    "test_loader2 = DataLoader(dataset=test_dataset2,\n",
    "                          batch_size=128,\n",
    "                          shuffle=True)"
   ],
   "metadata": {
    "id": "v0KPfIPW2OJl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "train_loader - MNIST에 대해서 train datset이 dataloader로 변환된 모습.  \n",
    "test_loader - MNIST에 대해서 test dataset이 dataloader로 변환된 모습.  \n",
    "\n",
    "train_loader2 - FashionMNIST에 대해서 train datset이 dataloader로 변환된 모습.  \n",
    "test_loader2 - FashionMNIST에 대해서 test dataset이 dataloader로 변환된 모습.  "
   ],
   "metadata": {
    "id": "pvlePlgW3Xff"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# resnet18 다운로드\n",
    "from torchvision import models\n",
    "\n",
    "# 학습된 모델 다운로드 (pretrained=True)\n",
    "resnet18_pretrained = models.resnet18(pretrained=True)"
   ],
   "metadata": {
    "id": "JnH_o-B62zwQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "resnet18_pretrained"
   ],
   "metadata": {
    "id": "PBom8B769QID"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# freeze\n",
    "for param in resnet18_pretrained.parameters():\n",
    "    # resnet18의 parmeter의 학습을 하지 않도록 만들기\n",
    "    param.requires_grad = False\n",
    "\n",
    "# resnet18\n",
    "# CNN(freeze) - 11만개\n",
    "# FC2 - 8000개 가량\n",
    "\n",
    "# 뒤쪽에 FC 레이어를 변경\n",
    "resnet18_pretrained.fc = nn.Sequential(\n",
    "    nn.Linear(in_features=512, out_features=10),\n",
    "    nn.Softmax()\n",
    ")\n",
    "\n",
    "# 기본적인 resnet18의 경우 3x224x224의 입력을 받기 때문에\n",
    "# 맨 처음 convolution을 1채널만 받도록 변경은 해줘야한다\n",
    "\n",
    "resnet18_pretrained.conv1 = nn.Conv2d(in_channels=1, out_channels=64,\n",
    "                                      kernel_size=(7, 7),\n",
    "                                      stride=(2, 2),\n",
    "                                      padding=(3, 3),\n",
    "                                      bias=False)\n",
    "\n",
    "# 수정된 resnet18_pretrained라는 모델을 device로 보내서 학습에 사용할 수 있도록 함\n",
    "resnet18_pretrained.to(device)"
   ],
   "metadata": {
    "id": "qR3IQ-Zn38-L"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# summary(resnet18_pretrained, (1, 224, 224))"
   ],
   "metadata": {
    "id": "QOlfxb6O3_60"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 수정된 resnet18모델에 대해서 fashMNIST에 대해서 학습 진행\n",
    "train(resnet18_pretrained, train_loader2)"
   ],
   "metadata": {
    "id": "bZm-b_o_4DtA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test(resnet18_pretrained, test_loader2)"
   ],
   "metadata": {
    "id": "z9riHnwe4dzU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resnet18_pretrained2 = models.resnet18(pretrained=True)\n",
    "\n",
    "# freeze Fine Tuning에서는 freeze하는 부분을 진행하지 않는다\n",
    "# for param in resnet18_pretrained.parameters():\n",
    "#   param.requires_grad = False\n",
    "\n",
    "# ResNet18\n",
    "# CNN\n",
    "# FC2\n",
    "\n",
    "# 뒤쪽에 FC 레이어를 변경\n",
    "resnet18_pretrained2.fc = nn.Sequential(\n",
    "    nn.Linear(512, 10),\n",
    "    nn.Softmax()\n",
    ")\n",
    "\n",
    "resnet18_pretrained2.conv1 = nn.Conv2d(in_channels=1, out_channels=64,\n",
    "                                       kernel_size=(7, 7),\n",
    "                                       stride=(2, 2),\n",
    "                                       padding=(3, 3),\n",
    "                                       bias=False)\n",
    "\n",
    "resnet18_pretrained2.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# summary(resnet18_pretrained2, input_size=(1, 224, 224))"
   ],
   "metadata": {
    "id": "J4Ggc4Gb4IrP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train(resnet18_pretrained2, train_loader2)"
   ],
   "metadata": {
    "id": "ALiXS7eU4s2V"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test(resnet18_pretrained2, test_loader2)"
   ],
   "metadata": {
    "id": "stPbUzg_4uKS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Fine Tuning\n",
    "resnet18_pretrained3 = models.resnet18(pretrained=True)\n",
    "\n",
    "# 뒤쪽에 FC 레이어를 변경\n",
    "resnet18_pretrained3.fc = nn.Sequential(\n",
    "    nn.Linear(512, 10),\n",
    "    nn.Softmax()\n",
    ")\n",
    "\n",
    "# 첫번째 convolution을 변환\n",
    "resnet18_pretrained3.conv1 = nn.Conv2d(in_channels=1, out_channels=64,\n",
    "                                       kernel_size=(7, 7),\n",
    "                                       stride=(2, 2),\n",
    "                                       padding=(3, 3),\n",
    "                                       bias=False)\n",
    "\n",
    "resnet18_pretrained3.to(device)"
   ],
   "metadata": {
    "id": "5WjIkCydAHQ1",
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test(resnet18_pretrained3, test_loader2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train(resnet18_pretrained3, test_loader2)"
   ],
   "metadata": {
    "id": "xGNLaU_4AZxZ",
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test(resnet18_pretrained3, test_loader2)"
   ],
   "metadata": {
    "id": "ufdhtqruAl91",
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
